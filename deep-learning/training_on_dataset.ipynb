{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# prompt: remove sample_data folder\n",
        "\n",
        "!rm -rf sample_data"
      ],
      "metadata": {
        "id": "nkqoUbYaSVoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# constants\n",
        "RAW_DATASET_PATH = 'myntra_products.csv'\n",
        "PROCESSED_DATASET_PATH = 'processed_dataset.csv'\n",
        "# Set the directory where the model will be saved\n",
        "MODEL_DIR = '/content/drive/machine-learning/vit_model'\n"
      ],
      "metadata": {
        "id": "5qGhejdsVfgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHsjjicQZrwH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.optim.adamw import AdamW\n",
        "from torch.optim.lr_scheduler import StepLR\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the dataset\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Parameters\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = (100, 100)  # Resize images to 100x100 for faster processing\n",
        "CACHE_DIR = \"cached_images\"\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('myntra_products.csv')\n",
        "\n",
        "def download_and_cache_image(image_url, cache_dir=CACHE_DIR):\n",
        "    \"\"\"Download image and cache it locally.\"\"\"\n",
        "    filename = os.path.join(cache_dir, os.path.basename(image_url).split('?')[0])\n",
        "    if not os.path.exists(filename):\n",
        "        try:\n",
        "            response = requests.get(image_url)\n",
        "            image = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "            image = image.resize(IMAGE_SIZE)\n",
        "            image.save(filename)\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading {image_url}: {e}\")\n",
        "            return None\n",
        "    return filename\n",
        "\n",
        "def get_dominant_color(image_path, k=4):\n",
        "    \"\"\"Use KMeans to find the dominant color.\"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        return None\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = image.reshape((image.shape[0] * image.shape[1], 3))\n",
        "\n",
        "    # Use KMeans clustering\n",
        "    clt = KMeans(n_clusters=k)\n",
        "    clt.fit(image)\n",
        "\n",
        "    # Find the largest cluster\n",
        "    counts = np.bincount(clt.labels_)\n",
        "    dominant_color = clt.cluster_centers_[counts.argmax()]\n",
        "\n",
        "    # Convert to hex\n",
        "    dominant_color_hex = \"#{:02x}{:02x}{:02x}\".format(int(dominant_color[0]), int(dominant_color[1]), int(dominant_color[2]))\n",
        "    return dominant_color_hex\n",
        "\n",
        "def batch_process_images(df, batch_size=BATCH_SIZE):\n",
        "    \"\"\"Batch process images and extract colors.\"\"\"\n",
        "    colors = []\n",
        "    for start in tqdm(range(0, len(df), batch_size), desc=\"Processing Batches\"):\n",
        "        batch = df.iloc[start:start + batch_size]\n",
        "        for _, row in batch.iterrows():\n",
        "            image_url = row['image_url']\n",
        "            # Download and cache image\n",
        "            cached_image_path = download_and_cache_image(image_url)\n",
        "            if cached_image_path:\n",
        "                color = get_dominant_color(cached_image_path)\n",
        "            else:\n",
        "                color = \"N/A\"\n",
        "            colors.append(color)\n",
        "    return colors\n",
        "\n",
        "# Add colors to the dataset\n",
        "df['colors'] = batch_process_images(df)\n",
        "\n",
        "# Save the updated dataset\n",
        "df.to_csv('myntra_products_with_colors.csv', index=False)\n",
        "print(\"Dataset updated with colors and saved successfully!\")\n"
      ],
      "metadata": {
        "id": "CAG_qbukVWSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "FT0s3YjgYvbC",
        "outputId": "b3c0504d-850e-4ccf-f2e1-389ba87ef2ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.00016135239695124696\n",
            "Epoch 2/3, Loss: 1.992046260662011e-08\n",
            "Epoch 3/3, Loss: 1.5682986936882415e-08\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "[Errno 95] Operation not supported: '/content/drive/machine-learning'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f183a04f2cd2>\u001b[0m in \u001b[0;36m<cell line: 99>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;31m# Save the model and feature extractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 95] Operation not supported: '/content/drive/machine-learning'"
          ]
        }
      ],
      "source": [
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(PROCESSED_DATASET_PATH)\n",
        "\n",
        "# Data Preparation\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# Update Dataset class to include color feature\n",
        "class FashionDataset(Dataset):\n",
        "    def __init__(self, dataframe, feature_extractor, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.transform = transform\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.dataframe['gender_encoded'] = self.label_encoder.fit_transform(self.dataframe['gender'])\n",
        "\n",
        "        # Encode color feature\n",
        "        self.scaler = StandardScaler()\n",
        "        self.color_features = self.extract_color_features(self.dataframe['colors'])\n",
        "\n",
        "    def extract_color_features(self, color_column):\n",
        "        \"\"\"Convert hex color to RGB and scale the values.\"\"\"\n",
        "        color_values = color_column.apply(lambda x: int(x[1:], 16) if isinstance(x, str) and x.startswith('#') else 0)\n",
        "        rgb_values = [[(val >> 16) & 255, (val >> 8) & 255, val & 255] for val in color_values]\n",
        "        return self.scaler.fit_transform(rgb_values)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        image_url = row['image_url']\n",
        "        color_features = torch.tensor(self.color_features[idx], dtype=torch.float)\n",
        "\n",
        "        # Download and process the image\n",
        "        response = requests.get(image_url)\n",
        "        image = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "\n",
        "        # Apply transformations\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Encode the label\n",
        "        label = row['gender_encoded']\n",
        "\n",
        "        # Extract pixel values using feature extractor\n",
        "        pixel_values = self.feature_extractor(images=image, return_tensors=\"pt\").pixel_values\n",
        "\n",
        "        return {\n",
        "            'pixel_values': pixel_values.squeeze(),\n",
        "            'color_features': color_features,\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "model_name_or_path = 'google/vit-base-patch16-224-in21k'\n",
        "\n",
        "# Initialize the feature extractor\n",
        "feature_extractor = AutoImageProcessor.from_pretrained(model_name_or_path, use_fast=True)\n",
        "\n",
        "# Define image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Create dataset and dataloader\n",
        "dataset = FashionDataset(df, feature_extractor, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Model Setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    model_name_or_path,\n",
        "    num_labels=len(df['gender'].unique())\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "# Training setup\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.1)\n",
        "\n",
        "\n",
        "# Training Loop\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        pixel_values = batch['pixel_values'].to(device)\n",
        "        color_features = batch['color_features'].to(device)\n",
        "        labels = batch['labels'].to(device).float()\n",
        "\n",
        "        # Concatenate image features with color features\n",
        "        image_features = torch.cat((pixel_values.view(pixel_values.size(0), -1), color_features), dim=1)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(pixel_values=image_features, labels=labels)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Step the scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(dataloader)}\")\n",
        "\n",
        "# Save the model and feature extractor\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "    os.makedirs(MODEL_DIR)\n",
        "\n",
        "model.save_pretrained(MODEL_DIR)\n",
        "feature_extractor.save_pretrained(MODEL_DIR)\n",
        "print(f\"Model saved successfully to {MODEL_DIR}!\")\n",
        "\n",
        "# To reload the model and feature extractor for further training\n",
        "# model = AutoModelForImageClassification.from_pretrained(MODEL_DIR).to(device)\n",
        "# feature_extractor = AutoImageProcessor.from_pretrained(MODEL_DIR)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}